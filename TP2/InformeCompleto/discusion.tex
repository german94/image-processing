\section{Discusión}
%Se incluirá aquí un análisis de los resultados obtenidos en la sección anterior (se analizará
%su validez, coherencia, etc.). Deben analizarse como míınimo los ítems pedidos en el
%enunciado. No es aceptable decir que “los resultados fueron los esperados”, sin hacer
%clara referencia a la teoría la cual se ajustan. Además, se deben mencionar los resul-
%tados interesantes y los casos “patológicos” encontrados.





\subsection{Elección de los K}
Con respecto a la hipótesis N 3, que establecía que corriendo cualquiera de los 2 métodos implementados(kNN y kNN+PCA) fijando k y $\alpha$, a mayor valor
de K mayor porcentaje de tasas, procederemos primero a observar los resultados de kNN+PCA.\\ Comparando las tasas de efectivad resultantes de usar K=2 contra K=10 y K=20, se nota claramente que las de K=2 son menores que las de los otros dos valores de K. Esto es consecuencia principal del uso de la técnica de K-Fold Cross Validation, ya que con un valor K chico nuestra partición de la base de entrenamiento se divide en partes mas grandes, en consecuencia la longitud de la base de test tiende a ser igual a la base de entrenamiento. Dicho en otros términos, tenemos menos elementos en la base de entrenamiento para entrenar nuestro algoritmo y menos permutaciones sobre cuales elementos los consideramos parte del test. Esto es la principal causa de que con K=2 obtengamos los menores valores de la tasa de efectivida. Para que la tasa de efectividad tienda a 1, es necesario contar con una base lo más extensa posible. Y además al aumentar K, tenemos mas combinacion de particiones posibles y un entrenamiento más profundo. En este caso, la disminucion de la misma no se ve afectada por el valor que tome k y alpha. \\Hasta aqui la hipótesis se confirmaría, pero al analizar y comparar las tasas de K=10 contra K=20, observamos que aca si incide el valor que tome k. Para k con valores chicos, se ve una diferencia de la tasa cuando saltamos de K=10 a K=20, pero a medida que k aumenta, las tasas empiezan a comportarse de manera similar, teniendo vaivenes para algunos k, en el que la tasa de K=10 le gana a K=20 o viceversa. Ante esta situación, decidimos observar más detalladamente los datos de la experimentación y logramos ver que para k grandes y K=20, la muestra de las tasas de cada partición posee una mayor varianza, es decir que los valores tienen mayores fluctuaciones en comparación a la media de la muestra. Realizando un análisis más intensivo, deducimos que esto se debe a que a mayor valor de K, tengo mas elementos de entrenamiento, y a su vez a mayor valor de k, tengo más elemento que entrarán en la definición de vecinos más cercanos, pudiendo aqui encontrar elementos que no son del mismo label que el elemento en estudio y así alternar notablemente la tasa de efectividad en cada una de las particiones.\\
Como último dato, el valor de $\alpha$ no incide en las tasas de efectividad entre diferentes K, es decir, para un $\alpha$ fijo, a medida que se aumenta el valor de K, aumenta la tasa.\\
Con respecto al método de kNN, la elección de los K, se comporta de la misma manera y tiene las mismas consecuencias que en el método de kNN+PCA.
Finalmente se pordría concluir que la hipótesis queda parcialmente verificada, ya que la única parte que se refuto de la misma fue la parte de mantener k constante.

\subsection{Competencia Kaggle}
Para realizar nuestro submission en la página de Kaggle, a la competencia de Digit Recognizer, modificamos levemente el codigo de nuestro programa. El mismo se encuentra en la carpeta Kaggle. Las modificaciones se deben a que en este caso, la base de test proporcionada por la página no tiene labels, no utilizamos el método de K-Fold Cross Validation, la funcion kNN ahora tiene que devolver las predicciones de los dígitos, entre otras cosas.\\
Luego de toda la experimentación concluímos que los mejores parámetros, en cuanto tiempo y eficacia, para correr el programa son algún k y $\alpha$ cercanos a:
\begin{itemize}
\item $\alpha$ = 50
\item $k$ = 2
\end{itemize}

A continuación probaremos con valores cercanos a estos parámetros para estudiar la efectividad que nos proporciona el sistema de Kaggle.
\begin{itemize}
	\item Con k=2 y $\alpha$=50, tuvimos una efectividad de 0.96686
	\item Con k=3 y $\alpha$=50, tuvimos una efectividad de 0.96857
	\item Con k=3 usando solo kNN, tuvimos una efectividad de 0.97200
	\item Con k=4 y $\alpha$=50, tuvimos una efectividad de 0.97286
\end{itemize}